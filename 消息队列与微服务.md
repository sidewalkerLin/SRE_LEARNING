## 一、ZooKeeper







## 二、Kafka

### 1、Kafka概述

#### 1.1、消息队列



#### 1.2、消息队列应用场景



#### 1.3、消息队列的2种模式

点对点模式



发布者订阅者模式



#### 1.4、Kafka角色

**(1)Producer**

Producer是消息生产者，就是向kafka broker发消息的客户端，生产者负责将记录分配到topic的指定 partition中。

将记录分配到哪个分区中由生产者来决定，有俩种发送机制：

- 轮询：先随机到某一个partition上一直持续的写，大概写个十分钟，再随机到一个partition再去写，所以一般建议生产消息都按照建个key来按照hash去分，还可以自定义按照key怎么去分。
- key的hash：如果key为null，就是轮询，否则就是按照key的hash

在Kafka中，每条消息记录都是一个key-value键值对，这个键值对是生产者在发送消息指定的。默认情况下，Kafka使用的是DefaultPartitioner，如果生产者在发送消息时指定了key，DefaultPartitioner会对key进行hash，然后用hash值对分区数进行取模运算，得到的结果就是消息应该发送到的分区。这样可以保证相同key的消息总是被发送到同一个分区。

例如，假设你有一个Kafka主题，这个主题有4个分区，分区编号是0, 1, 2, 3。当你发送一条带有key的消息时，DefaultPartitioner会对key进行hash，假设得到的hash值是10。然后，DefaultPartitioner会用10对4（分区数）进行取模运算，得到的结果是2。所以，这条消息会被发送到分区2。

**(2)Consumer**

Consumer是消息消费者，向kafka broker取消息的客户端，每个消费者都要维护自己读取数据的offset。

- 每个consumer都有自己的消费者组group
- 同一个消费者组内的消费者在消费同一个topic时，这个topic中相同的数据只能被消费一次
- 不同的消费者组消费同一个topic互不影响
- 低版本0.9之前将offset保存在Zookeeper中，0.9及之后保存在Kafka的“__consumer_offsets”主题中

**(3)Broker**

一台kafka服务器节点就是一个broker，负责处理消息读、写请求，存储消息，在kafka cluster这一层这里，其实里面是有很多个broke。一个集群由多个broker组成，一个broker可以容纳多个topic。

broker是组成kafka集群的节点，broker之间没有主从关系，各个broker之间的协调依赖于zookeeper，如数据在哪个节点上之类的Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线，所有topic的分区副本分配和leader选举等工作。

Controller的管理工作都是依赖于Zookeeper的。

**(4)Topic**

一个topic是opic就是一个消息队列，一个topic又分为多个分区。可以讲topic类比为数据库中的一个库，而分区是这个库中的表

**(5)Consumer group**

每个消费者都会使用一个消费组名称来进行标识，同一个组中的不同的消费者实例，可以分布在多个进程或多个机器上。

消费者组，由多个consumer组成。

- 一个topic可以有多个消费者组。topic的消息会复制（不是真的复制，是概念上的）到所有的CG，但每个partion只会把消息发给该CG中的一个consumer。
- 消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个消费者消费；
- 消费者组之间互不影响。
- 所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。
- 如果所有的消费者实例在同一消费组中，消息记录会负载平衡到每一个消费者实例（单播）。即每个消费者可以同时读取一个topic的不同分区

消费者组是kafka用来**实现一个topic消息的广播（发给所有的消费者）和单播（发给任意一个消费者）**的手段。

- 如果需要实现广播，只要每个消费者有一个独立的消费者组就可以了。
- 如果需要实现单播，只要所有的消费者在同一个消费者组。用消费者组还可以将消费者进行自由的分组而不需要多次发送消息到不同的topic。

**(6)Partition**

Partition是物理上的概念，每个 topic 分割为一个或多个partition，即一个topic切分为多份, 当创建 topic 时可指定 partition 数量， partition的表现形式就是一个一个的文件夹,该文件夹下存储该partition的数据和索引文件，分区的作用还可以实现负载均衡，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的,一般Partition数不要超过节点数，注意同一个partition数据是有顺序的,partition中的每条消息都会被分配一个有序的id（offset），但不同的 partition则是无序的。

- partition可以很简单想象为一个文件，partition对应磁盘上的目录，当数据发过来的时候它就往这个partition上面追加，消息不经过内存缓冲，直接写入文件

kafka为每个主题维护了分布式的分区(partition)日志文件，每个partition在kafka存储层面是append log。任何发布到此partition的消息都会被追加到log文件的尾部，在分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，也就是我们的offset,offset是一个long型的数字，我们通过这个offset可以确定一条在该partition下的唯一消息。在partition下面是保证了有序性，但是在topic下面没有保证有序性。

**(7)Replication**

副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。

日志的分区partition （分布）在Kafka集群的服务器上。每个服务器在处理数据和请求时，共享这些分区。每一个分区都会在已配置的服务器上进行备份，确保容错性。

每个分区都有一台 server 作为 “leader”，零台或者多台server作为 follwers 。leader server 处理一切对 partition （分区）的读写请求，而follwers只需被动的同步leader上的数据。当leader宕机了，followers 中的一台服务器会自动成为新的 leader。通过这种机制，既可以保证数据有多个副本，也实现了一个高可用的机制！

同一个partition可能会有多个replication（对应 server.properties 配置中的 default.replication.factor=N）。没有replication的情况下，一旦broker 宕机，其上所有 partition 的数据都不可被消费，同时producer也不能再将数据存于其上的patition。引入replication之后，同一个partition可能会有多个replication，而这时需要在这些replication之间选出一个leader，producer和consumer只与这个leader交互，其它replication作为follower从leader 中复制数据。

基于安全考虑，每个分区的Leader和follower一般会错在在不同的broker!

另外，Kafka中的副本数包括主分片数,而ES中的副本数不包括主分片数。

**(8)AR**

 Assigned Replicas，分区中的所有副本的统称，包括leader和 follower，AR= lSR+ OSR

**(9)ISR**

ln Sync Replicas，所有与leader副本保持同步的副本 follower和leader本身组成的集合，包括leader和 follower，是AR的子集

**(10)OSR**

out-of-Sync Replied，所有与leader副本同步不能同步的 follower的集合，是AR的子集

**(11)Offset**

kafka的存储文件都是按照offset.kafka来命名，用offset做名字的好处是方便查找。例如你想找位于2049的位置，只要找到2048.kafka的文件即可。当然the first offset就是00000000000.kafka

数据会按照时间顺序被不断第追加到分区的一个结构化的commit log中！每个分区中存储的记录都是有序的，且顺序不可变！

这个顺序是通过一个称之为offset的id来唯一标识！因此也可以认为offset是有序且不可变的！

在每一个消费者端，会唯一保存的元数据是offset（偏移量）,即消费在log中的位置，偏移量由消费者所控制。通常在读取记录后，消费者会以线性的方式增加偏移量，但是实际上，由于这个位置由消费者控制，所以消费者可以采用任何顺序来消费记录。例如，一个消费者可以重置到一个旧的偏移量，从而重新处理过去的数据；也可以跳过最近的记录，从"现在"开始消费。

这些细节说明Kafka 消费者是非常廉价的—消费者的增加和减少，对集群或者其他消费者没有多大的影响。比如，你可以使用[命令行工具](https://cloud.tencent.com/product/cli?from_column=20065&from=20065)，对一些topic内容执行 tail操作，并不会影响已存在的消费者消费数据。

1.2、Kafka工作机制

在Kafka的设计中，每个主题可以被分割成多个分区，每个分区都有一个leader和多个follower。leader负责处理所有的读写请求，而follower则复制leader的数据以提供冗余备份。

当你向Kafka的某个主题写入数据时，这些数据会被发送到该主题的一个分区（由Kafka的生产者客户端决定）。这个分区的leader将数据写入它的日志，并且将数据发送给它的所有follower。每个follower都将数据写入它自己的日志，并向leader确认它已经接收到数据。一旦所有的follower都确认接收到数据，leader就会向生产者客户端确认数据已经被写入。

在你的例子中，如果leader0在服务器A上，而它的follower在服务器B和C上，那么当你向leader0写入数据时，这些数据会被复制到服务器B和C上。这样，即使服务器A出现故障，你仍然可以从服务器B或C上的follower读取数据，从而实现高可用性和数据冗余。

需要注意的是，Kafka的这种复制机制需要一个可靠的网络环境，以确保数据可以被准确地复制到所有的follower。此外，为了保持数据的一致性，follower必须能够及时地复制leader的数据。如果follower落后于leader太多，它可能会被剔除出副本集，不再作为备份。

### 2、Kafka命令行

#### 2.1、命令参数

| 参数                 | 描述                                                         |
| -------------------- | ------------------------------------------------------------ |
| --bootstrap-server   | 指定连接的kafka broker的ip:port，一般在生产环境中指定多个并用,隔开 |
| --topic              | 指定操作(crud)的topic的名称                                  |
| --create             | 创建主题                                                     |
| --delete             | 删除主题                                                     |
| --alter              | 修改主题                                                     |
| --list               | 查看所有主题                                                 |
| --describe           | 查看主题详细描述                                             |
| --partitions         | 设置分区数                                                   |
| --replication-factor | 设置分区副本数量                                             |
| --config             | 更新系统默认配置                                             |

#### 2.1、创建topic

```bash
kafka-topics.sh --bootstrap-server broker_ip:9092 --create --partitions 3 --replication-factor 2 --topic topic_name

#生产环境会填写多个broker的ip，防止连接的kafka broker宕机
kafka-topics.sh --bootstrap-server broker_ip1:9092,broker_ip2:9092 --create --partitions 3 --replication-factor 2 --topic topic_name
```

#### 2.2、获取所有topic信息

```bash
kafka-topics.sh --bootstrap-server broker_ip:9092 --list
```

#### 2.3、查看topic详情

```bash
kafka-topics.sh --bootstrap-server broker_ip:9092 --describe --topic topic_name
```

#### 2.4、删除topic

```bash
kafka-topics.sh --bootstrap-server broker_ip:9092 --delete --topic topic_name
```

#### 2.5、修改topic分区数量

<font color='#ff0000'> **注意：分区数量只能增加不能减少**</font>

如果要减少分区数量，就会涉及到删除分区，那么被删除的数据怎么办？直接不保留，

(1)

(2)

(3)

```bash
kafka-topics.sh --bootstrap-server broker_ip:9092 --alter --topic topic_name --partitions 5
```

#### 2.6、创建一个生产者

```bash

```

#### 2.7、创建一个消费者

```bash

```

### 3、Kafka生产者



怎么理解toptic？



topic的每个分区的数据量是否是均分等量的？



为什么会有消费者组？



同一时间消费者组中的只能有一个消费者消费一个分区中的信息？



消费者订阅的是topic还是订阅的topic的分区的消息？



分区数量以及副本数量问题？



2.8.0以后可以不用安装zk

缓冲 

解耦 ：不同数据源都集成到kafka中，上游平台直接从kafka获取数据即可，否则要自己实现各种数据源的对接

异步通信



点对点模式：只有一个topic主题，消费者主动拉取数据，消息收到后清除消息

发布者订阅者模式：

可以有多个topic主题，比如浏览、评论、订阅等；消费者消费数据后不删除数据；消费者相互独立，都可以消费到数据

![image-20231124162910376](C:\Users\26926\AppData\Roaming\Typora\typora-user-images\image-20231124162910376.png)

kafka/bin  启动停止脚本等

kafka/config配置信息



主题命令

生产者命令

消费者命令



三、Dubbo

